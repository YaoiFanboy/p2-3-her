{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94732ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_value = 0\n",
    "                \n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = 1 / (1 + np.exp(-linear_output))\n",
    "        #return np.where(y_pred>=0.5, 1, 0)\n",
    "        return y_pred\n",
    "    \n",
    "    def update(self, x_i, y_i, y_pred):\n",
    "        error = y_i - y_pred\n",
    "        derivative = y_pred * (1 - y_pred)\n",
    "        update = self.learning_rate * error * derivative\n",
    "        self.weights += update * x_i\n",
    "        self.bias += update\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        self.loss_value = self.mean_squared_error(y, y_pred)\n",
    "        return self.loss_value\n",
    "    \n",
    "    def fit(self, X, y,epochs):\n",
    "        self.epochs = epochs\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # initialize weights and bias with random values\n",
    "        self.weights = np.random.normal(size=n_features)\n",
    "        self.bias = np.random.normal()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_pred = 1 / (1 + np.exp(-linear_output))\n",
    "                \n",
    "                # update weights and bias\n",
    "                self.update(x_i, y[idx], y_pred)\n",
    "                \n",
    "            # calculate loss\n",
    "            err = self.loss(X, y)\n",
    "            #print(f\"Epoch {epoch+1}/{self.epochs}, loss={err}\")\n",
    "    \n",
    "    def fit_with_target(self, X, y, target_loss=0.01):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # initialize weights and bias with random values\n",
    "        self.weights = np.random.normal(size=n_features)\n",
    "        self.bias = np.random.uniform(-1,1)\n",
    "        \n",
    "        while True:\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_pred = 1 / (1 + np.exp(-linear_output))\n",
    "                # update weights and bias\n",
    "                self.update(x_i, y[idx], y_pred)\n",
    "            \n",
    "            # calculate loss\n",
    "            err = self.loss(X, y)\n",
    "            #print(f\"loss = {err}\")\n",
    "            \n",
    "            if err <= target_loss:\n",
    "                break\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Perceptron(weights={self.weights}, bias={self.bias})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4ca9e",
   "metadata": {},
   "source": [
    "### And Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ad63fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.51516807e-09 1.08479375e-03 1.08473263e-03 9.98716811e-01]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_train = np.array([a and b for a, b in x_train])\n",
    "\n",
    "# network\n",
    "and_per = Perceptron(65)\n",
    "# train\n",
    "and_per.fit_with_target(x_train, y_train, target_loss=0.000001)\n",
    "\n",
    "# test\n",
    "out = and_per.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54996ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(weights=[13.48240304 13.48245944], bias=-20.307739464333174)\n"
     ]
    }
   ],
   "source": [
    "print(and_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59427cd6",
   "metadata": {},
   "source": [
    "### XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df6e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2500011672421212\n",
      "Perceptron(weights=[ 12.98516316 -20.03861951], bias=-6.390870961134524)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_train = np.array([a ^ b for a, b in x_train])\n",
    "\n",
    "# network\n",
    "xor_per = Perceptron(55)\n",
    "\n",
    "# train\n",
    "xor_per.fit(x_train, y_train, epochs = 10000)\n",
    "\n",
    "print(xor_per.loss_value)\n",
    "print(xor_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd898cb1",
   "metadata": {},
   "source": [
    "XOR-poortverlies kan niet worden geconvergeerd naar 0 met single layer perceptrons, we moeten er moet een multi layer perceptron gebruikt worden voor de XOR-poort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f351015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd905b2",
   "metadata": {},
   "source": [
    "### Not Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7cd76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.98904484e-01 8.94299867e-04]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[0],[1]])\n",
    "y_train = np.array([not a for a in x_train])\n",
    "\n",
    "# network\n",
    "not_per = Perceptron(55)\n",
    "\n",
    "# train\n",
    "not_per.fit_with_target(x_train, y_train, target_loss=0.000001)\n",
    "\n",
    "# test\n",
    "out = not_per.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce379f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.999642250337872e-07\n",
      "Perceptron(weights=[-13.83400802], bias=6.815433305440728)\n"
     ]
    }
   ],
   "source": [
    "print(not_per.loss_value)\n",
    "print(not_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd93aa3",
   "metadata": {},
   "source": [
    "### OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3804d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00149099 0.99905969 0.99905516 1.        ]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_train = np.array([a or b for a, b in x_train])\n",
    "\n",
    "# network\n",
    "or_per = Perceptron(55)\n",
    "\n",
    "# train\n",
    "or_per.fit_with_target(x_train, y_train, target_loss=0.000001)\n",
    "\n",
    "# test\n",
    "out = or_per.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ec3664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.999875731424587e-07\n",
      "Perceptron(weights=[13.47037763 13.4751807 ], bias=-6.506824454721083)\n"
     ]
    }
   ],
   "source": [
    "print(or_per.loss_value)\n",
    "print(or_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0762c7",
   "metadata": {},
   "source": [
    "### IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98be3dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True).frame\n",
    "\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ddfc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_i = iris[(iris[\"target\"] == 0) | (iris[\"target\"] == 2)]\n",
    "iris_ii = iris[(iris[\"target\"] == 1) | (iris[\"target\"] == 2)]\n",
    "\n",
    "iris_i_target = iris_i[\"target\"].values.tolist()\n",
    "iris_i_input = iris_i.drop(columns=\"target\").values.tolist()\n",
    "\n",
    "iris_ii_target = iris_ii[\"target\"].values.tolist()\n",
    "iris_ii_input = iris_ii.drop(columns=\"target\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8cc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_i_target = [1 if num == 2 else 0 for num in iris_i_target]\n",
    "iris_ii_target = [num - 1 for num in iris_ii_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb08122",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_i_input = np.array(iris_i_input)\n",
    "iris_ii_input = np.array(iris_ii_input)\n",
    "\n",
    "iris_i_target = np.array(iris_i_target)\n",
    "iris_ii_target = np.array(iris_ii_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b7575",
   "metadata": {},
   "source": [
    "### Classifier for Setosa and Versicolour types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f4b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "per = Perceptron(0.8)\n",
    "\n",
    "# train\n",
    "per.fit_with_target(iris_i_input, iris_i_target, target_loss = 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d622d9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.997496992735973e-07\n",
      "Perceptron(weights=[-1.29793201 -1.41336276  3.25119254  2.08648741], bias=-1.4173772670582656)\n"
     ]
    }
   ],
   "source": [
    "print(per.loss_value)\n",
    "print(per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174fa1b",
   "metadata": {},
   "source": [
    "### Classifier for Versicolour and Verginica types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f387aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "per = Perceptron(0.25)\n",
    "\n",
    "# train\n",
    "per.fit(iris_ii_input, iris_ii_target, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df29a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03398530537541339\n",
      "Perceptron(weights=[-4.92399405 -9.92345651 15.02495266 20.85360929], bias=-46.72905824593156)\n"
     ]
    }
   ],
   "source": [
    "print(per.loss_value)\n",
    "print(per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4bc02",
   "metadata": {},
   "source": [
    "##### Gegevens voor Versi-kleur en verginica zijn niet lineair te scheiden, we moeten een multi layer perceptron gebruiken om verlies naar 0 te convergeren. (Het verlies dat we hierboven krijgen, is ook acceptabel, aangezien we meer dan 97% nauwkeurigheid krijgen [rekening houdend met verlies = 0,03]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65e6fa",
   "metadata": {},
   "source": [
    "## P3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da499d7",
   "metadata": {},
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d45f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        weighted_sum = np.dot(self.weights, inputs) + self.bias\n",
    "        output = self.sigmoid(weighted_sum)\n",
    "        return output\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Neuron(weights={self.weights}, bias={self.bias})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8701f1ba",
   "metadata": {},
   "source": [
    "INVERT, AND and OR Gates met random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b4bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVERT:\n",
      " 0 -> 0.6224593312018546,\n",
      " 1 -> 0.3775406687981454\n",
      "AND:\n",
      " 00 -> 0.2689414213699951,\n",
      " 01 -> 0.3775406687981454, \n",
      " 10 -> 0.3775406687981454,\n",
      " 11 -> 0.5\n",
      "OR:\n",
      " 00 -> 0.3775406687981454,\n",
      " 01 -> 0.5, \n",
      " 10 -> 0.5,\n",
      " 11 -> 0.6224593312018546\n"
     ]
    }
   ],
   "source": [
    "# Initialize a neuron for the INVERT port\n",
    "invert_neuron = Neuron(weights = np.array([-1]), bias = 0.5 )\n",
    "\n",
    "# Initialize a neuron for the AND port\n",
    "and_neuron = Neuron(weights = np.array([0.5, 0.5]), bias = -1)\n",
    "\n",
    "# Initialize a neuron for the OR port\n",
    "or_neuron = Neuron(weights = np.array([0.5, 0.5]), bias = -0.5)\n",
    "\n",
    "# Test the neurons with some example inputs\n",
    "print(f\"INVERT:\\n 0 -> {invert_neuron.forward(np.array([0]))},\\n 1 -> {invert_neuron.forward(np.array([1]))}\")\n",
    "print(f\"AND:\\n 00 -> {and_neuron.forward(np.array([0, 0]))},\\n 01 -> {and_neuron.forward(np.array([0, 1]))}, \"\n",
    "      f\"\\n 10 -> {and_neuron.forward(np.array([1, 0]))},\\n 11 -> {and_neuron.forward(np.array([1, 1]))}\")\n",
    "print(f\"OR:\\n 00 -> {or_neuron.forward(np.array([0, 0]))},\\n 01 -> {or_neuron.forward(np.array([0, 1]))}, \"\n",
    "      f\"\\n 10 -> {or_neuron.forward(np.array([1, 0]))},\\n 11 -> {or_neuron.forward(np.array([1, 1]))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc022d",
   "metadata": {},
   "source": [
    "#### Zoals we kunnen zien, komt output niet overeen met de verwachte waarden. Om dit te corrigeren, initialiseren we de neuronen met betere parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1090b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVERT:\n",
      " 0 -> 0.9999999999999873,\n",
      " 1 -> 1.2664165549094016e-14\n",
      "AND:\n",
      " 00 -> 2.031092662734811e-42,\n",
      " 01 -> 1.2664165549094016e-14, \n",
      " 10 -> 1.2664165549094016e-14,\n",
      " 11 -> 0.9999999999999873\n",
      "OR:\n",
      " 00 -> 1.2664165549094016e-14,\n",
      " 01 -> 0.9999999999999873, \n",
      " 10 -> 0.9999999999999873,\n",
      " 11 -> 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a neuron for the INVERT port\n",
    "invert_neuron = Neuron(weights = np.array([-64]), bias = 32 )\n",
    "\n",
    "# Initialize a neuron for the AND port\n",
    "and_neuron = Neuron(weights = np.array([64, 64]), bias = -96)\n",
    "\n",
    "# Initialize a neuron for the OR port\n",
    "or_neuron = Neuron(weights = np.array([64, 64]), bias = -32)\n",
    "\n",
    "# Test the neurons with some example inputs\n",
    "print(f\"INVERT:\\n 0 -> {invert_neuron.forward(np.array([0]))},\\n 1 -> {invert_neuron.forward(np.array([1]))}\")\n",
    "print(f\"AND:\\n 00 -> {and_neuron.forward(np.array([0, 0]))},\\n 01 -> {and_neuron.forward(np.array([0, 1]))}, \"\n",
    "      f\"\\n 10 -> {and_neuron.forward(np.array([1, 0]))},\\n 11 -> {and_neuron.forward(np.array([1, 1]))}\")\n",
    "print(f\"OR:\\n 00 -> {or_neuron.forward(np.array([0, 0]))},\\n 01 -> {or_neuron.forward(np.array([0, 1]))}, \"\n",
    "      f\"\\n 10 -> {or_neuron.forward(np.array([1, 0]))},\\n 11 -> {or_neuron.forward(np.array([1, 1]))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9959acd",
   "metadata": {},
   "source": [
    "Ik heb meerdere waarden geprobeerd voor de bovenstaande poorten. Door meerdere waarden te gebruiken, vond ik patronen voor elke poort\n",
    "1) Voor Invert gate zijn gewichten (negatief) en bias (positief) proportioneel met 2 en de nauwkeurigheid verbetert terwijl het gewicht en de biaswaarden toenemen door de verhouding te behouden\n",
    "\n",
    "2) Voor EN-poort zijn gewichten (positief) en bias (negatief) proportioneel met 2/3 en de nauwkeurigheid verbetert terwijl het gewicht en de biaswaarden toenemen door de verhouding te behouden\n",
    "\n",
    "3) Voor OF-poortgewichten (positief) en bias (negatief) zijn proportioneel met 2 en de nauwkeurigheid verbetert terwijl het gewicht en de biaswaarden worden verhoogd door de verhouding te behouden\n",
    "\n",
    "Door dit patroon bereiken we 100% nauwkeurigheid voor elke poort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73896359",
   "metadata": {},
   "source": [
    "#### Initializing NOR gate with three inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7502a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOR:\n",
      " 000 -> 1.0,\n",
      " 001 -> 0.9999999999999873, \n",
      " 010 -> 0.9999999999999873,\n",
      " 011 -> 1.2664165549094016e-14, \n",
      " 100 -> 0.9999999999999873,\n",
      " 101 -> 1.2664165549094016e-14, \n",
      " 110 -> 1.2664165549094016e-14,\n",
      " 111 -> 2.031092662734811e-42\n"
     ]
    }
   ],
   "source": [
    "nor_neuron = Neuron(weights = np.array([-64, -64, -64]), bias = 96)\n",
    "\n",
    "# Test the NOR neuron with some example inputs\n",
    "print(f\"NOR:\\n 000 -> {nor_neuron.forward(np.array([0, 0, 0]))},\\n 001 -> {nor_neuron.forward(np.array([0, 0, 1]))}, \"\n",
    "      f\"\\n 010 -> {nor_neuron.forward(np.array([0, 1, 0]))},\\n 011 -> {nor_neuron.forward(np.array([0, 1, 1]))}, \"\n",
    "      f\"\\n 100 -> {nor_neuron.forward(np.array([1, 0, 0]))},\\n 101 -> {nor_neuron.forward(np.array([1, 0, 1]))}, \"\n",
    "      f\"\\n 110 -> {nor_neuron.forward(np.array([1, 1, 0]))},\\n 111 -> {nor_neuron.forward(np.array([1, 1, 1]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aecfe1a",
   "metadata": {},
   "source": [
    "##### Nor poort met 3 ingangen is moeilijk lineair te voorspellen het vereist training met backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848e2f9",
   "metadata": {},
   "source": [
    "### Neuron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46645ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = np.random.randn(num_inputs)\n",
    "        self.bias = np.random.randn()\n",
    "        self.delta_w = np.zeros(num_inputs)\n",
    "        self.delta_b = 0\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z = np.dot(self.weights, inputs) + self.bias\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_deriv(self, inputs):\n",
    "        z = np.dot(self.weights, inputs) + self.bias\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        self.weights += learning_rate * self.delta_w\n",
    "        self.bias += learning_rate * self.delta_b\n",
    "        self.delta_w = np.zeros_like(self.delta_w)\n",
    "        self.delta_b = 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Neuron(weights={self.weights}, bias={self.bias})\"\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs):\n",
    "        self.neurons = [Neuron(num_inputs) for _ in range(num_neurons)]\n",
    "        self.inputs = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.array([neuron.forward(inputs) for neuron in self.neurons])\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.update(learning_rate)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"NeuronLayer(neurons={self.neurons})\"\n",
    "\n",
    "\n",
    "class NeuronNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layer = Layer(layer_sizes[i+1], layer_sizes[i])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def backpropagate(self, target):\n",
    "        delta = target.copy()\n",
    "        for layer in reversed(self.layers):\n",
    "            for i, neuron in enumerate(layer.neurons):\n",
    "                output = layer.inputs\n",
    "                if len(self.layers) - 1 == self.layers.index(layer):\n",
    "                    error = delta[i] - neuron.forward(output)\n",
    "                    delta[i] = error * neuron.sigmoid_deriv(output)\n",
    "                    #delta[i] = error * neuron.sigmoid(neuron.bias + np.dot(output, neuron.weights)) * (1 - neuron.sigmoid(neuron.bias + np.dot(output, neuron.weights)))\n",
    "                else:\n",
    "                    error = np.dot(delta, [neuron.weights[j] for j in range(len(layer.neurons))])\n",
    "                    #error = np.dot(delta,neuron.weights)\n",
    "                    delta[i] = error * neuron.sigmoid_deriv(output)\n",
    "                    #delta[i] = error * neuron.sigmoid(neuron.bias + np.dot(output, neuron.weights)) * (1 - neuron.sigmoid(neuron.bias + np.dot(output, neuron.weights)))\n",
    "                neuron.delta_w += output * delta[i]\n",
    "                neuron.delta_b += delta[i]\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        for layer in self.layers:\n",
    "            layer.update(learning_rate)\n",
    "\n",
    "    def train(self, inputs, targets, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i, input in enumerate(inputs):\n",
    "                output = self.forward(input)\n",
    "                target = targets[i]\n",
    "                #print(target-output)\n",
    "                \n",
    "                self.backpropagate(target)\n",
    "                self.update_weights(learning_rate)\n",
    "            \n",
    "    def __str__(self):\n",
    "        description = \"Neuron Network:\\n\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            description += f\"Layer {i+1}:\\n\"\n",
    "            for j, neuron in enumerate(layer.neurons):\n",
    "                description += f\"  Neuron {j+1}: {neuron}\\n\"\n",
    "        return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a421e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure before training\n",
      "Neuron Network:\n",
      "Layer 1:\n",
      "  Neuron 1: Neuron(weights=[ 0.24478913 -1.82614308], bias=-0.7795586268241815)\n",
      "  Neuron 2: Neuron(weights=[-0.37462347 -2.03357138], bias=-1.8106762336604874)\n",
      "Layer 2:\n",
      "  Neuron 1: Neuron(weights=[-0.25209551 -1.57235996], bias=-0.5087379528677197)\n",
      "  Neuron 2: Neuron(weights=[-0.73114683  0.67118079], bias=0.203313926940386)\n",
      "\n",
      "Network Structure after training\n",
      "Neuron Network:\n",
      "Layer 1:\n",
      "  Neuron 1: Neuron(weights=[ 0.24478913 -1.82614308], bias=-0.7795586268241815)\n",
      "  Neuron 2: Neuron(weights=[-0.37462347 -2.03357138], bias=-1.8106762336604874)\n",
      "Layer 2:\n",
      "  Neuron 1: Neuron(weights=[-0.25209551 -1.57235996], bias=-0.5087379528677197)\n",
      "  Neuron 2: Neuron(weights=[-0.73114683  0.67118079], bias=0.203313926940386)\n",
      "\n",
      "Input: [0 0], Target: [0 0], Output: [0.30810238 0.51693581]\n",
      "Input: [0 1], Target: [0 1], Output: [0.36377368 0.54167687]\n",
      "Input: [1 0], Target: [0 1], Output: [0.31847371 0.50026659]\n",
      "Input: [1 1], Target: [1 0], Output: [0.36510578 0.53743501]\n"
     ]
    }
   ],
   "source": [
    "# Define inputs and corresponding targets for half-adder\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "targets = np.array([[0, 0], [0, 1], [0, 1], [1, 0]])\n",
    "\n",
    "# Create neural network with 2 input neurons, 2 hidden neurons, and 2 output neurons\n",
    "ha = NeuronNetwork([2, 2, 2])\n",
    "\n",
    "#Printing the Structure before training\n",
    "print(\"Network Structure before training\")\n",
    "print(ha)\n",
    "\n",
    "# Train the neural network on the half-adder problem\n",
    "ha.train(inputs, targets, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "#Printing the Structure after training\n",
    "print(\"Network Structure after training\")\n",
    "print(ha)\n",
    "\n",
    "# Test the trained neural network\n",
    "for i, input in enumerate(inputs):\n",
    "    output = ha.forward(input)\n",
    "    print(f\"Input: {input}, Target: {targets[i]}, Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d232517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08e7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7cad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
